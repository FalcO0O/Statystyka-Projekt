{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca101797",
   "metadata": {},
   "source": [
    "**Import modułów**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c30e719-f381-4c7c-9919-261c979be65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib. pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3f192d",
   "metadata": {},
   "source": [
    "### Wstępna analiza\n",
    "Do odpalenia poniższego kodu wymagane jest wykonanie importu modułów, oraz klas: Iris_analysis oraz Mushrooms_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32e0c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iris_preliminary_analysis:\n",
    "    # Wczytanie zbioru danych Iris\n",
    "    iris = load_iris()\n",
    "    target_column = \"species\"  # Nazwa kolumny dla etykiet klas\n",
    "    iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)  # Tworzenie DataFrame z danymi cech\n",
    "    iris_df[target_column] = iris.target  # Dodanie kolumny z etykietami klas\n",
    "\n",
    "    def plot_histograms(self):\n",
    "        # Wczytanie zbioru Iris\n",
    "        self.iris = load_iris()\n",
    "        iris_df = pd.DataFrame(self.iris.data, columns=self.iris.feature_names)  # Tworzenie DataFrame\n",
    "        iris_df[self.target_column] = self.iris.target  # Dodanie kolumny z etykietami klas\n",
    "\n",
    "        # Rysowanie histogramów dla każdej cechy\n",
    "        iris_df.hist(figsize=(10, 8), bins=25)\n",
    "        plt.suptitle(\"Histogramy cech w zbiorze Iris\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_pairplot(self):\n",
    "        # Tworzenie DataFrame z danymi cech\n",
    "        iris_df = pd.DataFrame(self.iris.data, columns=self.iris.feature_names)\n",
    "        iris_df['species'] = self.iris.target  # Dodanie kolumny z etykietami klas\n",
    "\n",
    "        # Mapowanie wartości liczbowych na nazwy gatunków\n",
    "        species_mapping = {0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"}\n",
    "        iris_df[self.target_column] = iris_df[self.target_column].map(species_mapping)\n",
    "\n",
    "        # Rysowanie pairplotu z kolorami dla każdej klasy\n",
    "        sns.pairplot(iris_df, hue=self.target_column, markers=[\"o\", \"s\", \"D\"])\n",
    "        plt.suptitle(\"Pairplot zbioru Iris\", y=1.02)\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_violin(self):\n",
    "        # Tworzenie DataFrame z danymi cech\n",
    "        iris_df = pd.DataFrame(self.iris.data, columns=self.iris.feature_names)\n",
    "        iris_df['species'] = self.iris.target  # Dodanie kolumny z etykietami klas\n",
    "\n",
    "        # Rysowanie violin plot dla każdej cechy\n",
    "        plt.figure(figsize=(12,6))\n",
    "        for i, col in enumerate(iris_df.columns[:-1]):  # Iteracja po cechach numerycznych\n",
    "            plt.subplot(2,2,i+1)  # Tworzenie podwykresów\n",
    "            sns.violinplot(x=iris_df[self.target_column], y=iris_df[col])\n",
    "            plt.title(f\"Violin plot dla {col}\")\n",
    "        \n",
    "        # Mapowanie wartości liczbowych na nazwy gatunków\n",
    "        species_mapping = {0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"}\n",
    "        iris_df[self.target_column] = iris_df[self.target_column].map(species_mapping)\n",
    "\n",
    "        plt.tight_layout()  # Dopasowanie układu wykresów\n",
    "        plt.show()\n",
    "\n",
    "    def plot_boxplot(self):\n",
    "        # Rysowanie boxplotów dla wszystkich cech\n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.boxplot(data=self.iris_df)\n",
    "        plt.title(\"Boxplot cech w zbiorze Iris\")\n",
    "        plt.show()\n",
    "\n",
    "# Utworzenie instancji klasy do analizy wstępnej zbioru Iris\n",
    "iris_pre_analysis = Iris_preliminary_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd7583c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mushrooms_preliminary_analysis:\n",
    "    # Ścieżka do pliku CSV z danymi o grzybach\n",
    "    file_path = \"./mushroom-classification/mushrooms.csv\"\n",
    "    \n",
    "    # Wczytanie danych do DataFrame\n",
    "    mushrooms = pd.read_csv(file_path)\n",
    "    \n",
    "    # Nazwa kolumny zawierającej klasy (jadalny/trujący)\n",
    "    target_column = 'class'        \n",
    "\n",
    "    def features_plots(self):\n",
    "        # Rysowanie wykresów słupkowych dla każdej cechy w zbiorze danych\n",
    "        for col in self.mushrooms.columns:\n",
    "            plt.figure(figsize=(6, 4))  # Ustawienie rozmiaru wykresu\n",
    "            sns.countplot(x=self.mushrooms[col])  # Tworzenie wykresu częstości wartości danej cechy\n",
    "            plt.title(f\"Rozkład wartości cechy: {col}\")  # Tytuł wykresu\n",
    "            plt.xticks(rotation=45)  # Obrót etykiet osi X dla lepszej czytelności\n",
    "            plt.show()\n",
    "\n",
    "    def poisonous_edible_plots(self):\n",
    "        # Rysowanie wykresów słupkowych dla cech w podziale na klasy jadalności\n",
    "        for col in self.mushrooms.columns[1:]:  # Pomijamy kolumnę \"class\"\n",
    "            plt.figure(figsize=(6, 4))  # Ustawienie rozmiaru wykresu\n",
    "            sns.countplot(x=self.mushrooms[col], hue=self.mushrooms[\"class\"])  # Tworzenie wykresu z podziałem na klasy\n",
    "            plt.title(f\"{col} w podziale na klasy (jadalne vs trujące)\")  # Tytuł wykresu\n",
    "            plt.xticks(rotation=45)  # Obrót etykiet osi X dla lepszej czytelności\n",
    "            plt.show()\n",
    "\n",
    "# Utworzenie instancji klasy do analizy wstępnej zbioru grzybów\n",
    "mushrooms_pre_analysis = Mushrooms_preliminary_analysis()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd799f1e",
   "metadata": {},
   "source": [
    "Analiza Mushrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421155b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykresy poszczególnych cech (w analizie wklejałem tylko te, które przedstawiają więcej niż 2 wartości. Dla binarnych wykresów tylko wstawiłem proporcję)\n",
    "mushrooms_pre_analysis.features_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykresy poszczególnych cech w zależności od bycia trującym (p - trujące, e - jadalne)\n",
    "mushrooms_pre_analysis.poisonous_edible_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c646d2",
   "metadata": {},
   "source": [
    "Analiza Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rysowanie histogramu\n",
    "iris_pre_analysis.plot_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rysowanie pairplotu\n",
    "iris_pre_analysis.plot_pairplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75016684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rysowanie wykresu wiolinowego\n",
    "iris_pre_analysis.plot_violin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nie skorzystałem z niego w analizie, ponieważ wykres wiolinowy lepiej ukazuje informacje \n",
    "iris_pre_analysis.plot_boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad5a85",
   "metadata": {},
   "source": [
    "### Klasa naiwnego klasyfikatora Bayesowskiego dla cech kategorycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8905ff3-f9d8-4bc4-ae28-228ca6c03e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_log_probability = {}  # Logarytmiczne prawdopodobieństwa a priori dla każdej klasy\n",
    "        self.conditional_log_probability = {}  # Logarytmiczne prawdopodobieństwa warunkowe cech względem klas\n",
    "        self.epsilon = None  # Bardzo mała liczba używana zamiast zera, mala po uzyciu potegi, aby uniknąć problemów z log(0)\n",
    "        self.target_column = None  # Nazwa kolumny, względem której dokonujemy predykcji\n",
    "\n",
    "    def fit(self, X_train, column_name, epsilon):\n",
    "        \"\"\"\n",
    "        Trenuje model na podstawie dostarczonego zbioru danych.\n",
    "\n",
    "        Parametry:\n",
    "        X_train - DataFrame zawierający dane treningowe\n",
    "        column_name - nazwa kolumny z etykietami (klasami)\n",
    "        epsilon - bardzo mała liczba używana zamiast zera, aby uniknąć problemów z mnożeniem zerowych prawdopodobieństw.\n",
    "        \n",
    "        Nie zwraca nic.\n",
    "        \"\"\"\n",
    "        y = X_train[column_name]\n",
    "        self.target_column = column_name\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # Obliczanie logarytmicznych prawdopodobieństw a priori dla każdej klasy\n",
    "        for class_label in y.unique():\n",
    "            self.class_log_probability[class_label] = np.log(len(y[y == class_label]) / len(y))\n",
    "\n",
    "        # Obliczanie logarytmicznych prawdopodobieństw warunkowych dla każdej cechy względem każdej klasy\n",
    "        for column in X_train.columns:\n",
    "            if column == column_name:\n",
    "                continue\n",
    "\n",
    "            self.conditional_log_probability[column] = {}\n",
    "            for value in X_train[column].unique():\n",
    "                self.conditional_log_probability[column][value] = {}\n",
    "                \n",
    "                if value == \"?\":\n",
    "                    continue\n",
    "                # Uwzglednienie braku wartosci\n",
    "                \n",
    "                for class_label in y.unique():\n",
    "                    feature_count = len(y[y == class_label])\n",
    "                    conditional_count = len(X_train[(y == class_label) & (X_train[column] == value)])\n",
    "\n",
    "                    if feature_count > 0 and conditional_count > 0:\n",
    "                        self.conditional_log_probability[column][value][class_label] = np.log(conditional_count / feature_count)\n",
    "                    else:\n",
    "                        self.conditional_log_probability[column][value][class_label] = epsilon  # Bardzo mała liczba zamiast log(0)\n",
    "\n",
    "    def predict_with_option(self, row_to_predict, return_single):\n",
    "        \"\"\"\n",
    "        Przewiduje klasy dla dostarczonego wiersza z opcją zwracania prawdopodobieństw.\n",
    "\n",
    "        Parametry:\n",
    "        row_to_predict - Series zawierający dane wejściowe do predykcji\n",
    "        return_single - jeśli True, zwraca pojedynczą przewidywaną klasę, jeśli False zwraca prawdopodobieństwa\n",
    "\n",
    "        Zwraca:\n",
    "        Jeśli return_single=True -> przewidywana klasa (str)\n",
    "        Jeśli return_single=False -> lista prawdopodobieństw dla każdej klasy\n",
    "        \"\"\"\n",
    "        log_probability_per_class = {}\n",
    "\n",
    "        # Obliczanie logarytmicznego prawdopodobieństwa dla każdej klasy\n",
    "        for class_label in self.class_log_probability:\n",
    "            log_probability = self.class_log_probability[class_label]\n",
    "\n",
    "            for column, value in row_to_predict.items():\n",
    "                if column == self.target_column:\n",
    "                    continue\n",
    "\n",
    "                if value in self.conditional_log_probability[column]:\n",
    "                    log_conditional_probability = self.conditional_log_probability[column][value].get(class_label, self.epsilon)\n",
    "                    log_probability += log_conditional_probability\n",
    "                else:\n",
    "                    log_probability += self.epsilon  # Brak warunku oznacza bardzo małe prawdopodobieństwo\n",
    "\n",
    "            log_probability_per_class[class_label] = log_probability\n",
    "\n",
    "        # Zwracanie wyniku w zależności od opcji return_single\n",
    "        if return_single:\n",
    "            return max(log_probability_per_class, key=log_probability_per_class.get)\n",
    "        else:\n",
    "            return {class_label: np.exp(log_prob) for class_label, log_prob in log_probability_per_class.items()}\n",
    "\n",
    "    def predict(self, row_to_predict):\n",
    "        \"\"\"\n",
    "        Przewiduje klasę dla pojedynczego wiersza danych.\n",
    "\n",
    "        Parametry:\n",
    "        row_to_predict - Series zawierający dane wejściowe do predykcji\n",
    "\n",
    "        Zwraca:\n",
    "        Przewidywana klasa (str)\n",
    "        \"\"\"\n",
    "        return self.predict_with_option(row_to_predict, True)\n",
    "\n",
    "    def predict_proba(self, row_to_predict):\n",
    "        \"\"\"\n",
    "        Zwraca prawdopodobieństwa dla każdej klasy dla pojedynczego wiersza danych.\n",
    "\n",
    "        Parametry:\n",
    "        row_to_predict - Series zawierający dane wejściowe do predykcji\n",
    "\n",
    "        Zwraca:\n",
    "        Słownik prawdopodobieństw dla każdej klasy\n",
    "        \"\"\"\n",
    "        return self.predict_with_option(row_to_predict, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6610f2",
   "metadata": {},
   "source": [
    "### Klasa naiwnego klasyfikatora Bayesowskiego dla cech ilościowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f35599da-b703-4d1a-9c79-19bddde9559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_log_probability = {}  # Logarytmiczne prawdopodobieństwa a priori dla każdej klasy\n",
    "        self.gaussian_parameters = {}  # Średnie i odchylenia standardowe cech względem klas\n",
    "        self.target_column = None  # Nazwa kolumny z etykietami klas\n",
    "        self.epsilon = None  # Bardzo mała liczba, aby uniknąć log(0)\n",
    "\n",
    "    def fit(self, X_train, column_name, epsilon):\n",
    "        \"\"\"\n",
    "        Trenuje model Gaussowskiego Naive Bayes na podstawie danych treningowych.\n",
    "\n",
    "        Parametry:\n",
    "        X_train - DataFrame zawierający dane treningowe\n",
    "        column_name - nazwa kolumny z etykietami (klasami)\n",
    "        epsilon - bardzo mała liczba używana zamiast zera, aby uniknąć problemów z logarytmowaniem zerowych prawdopodobieństw\n",
    "\n",
    "        Nie zwraca nic.\n",
    "        \"\"\"\n",
    "        y = X_train[column_name]\n",
    "        self.target_column = column_name\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # Obliczanie logarytmicznych prawdopodobieństw a priori dla każdej klasy\n",
    "        for class_label in y.unique():\n",
    "            self.class_log_probability[class_label] = np.log(len(y[y == class_label]) / len(y))\n",
    "\n",
    "        # Obliczanie średnich i odchyleń standardowych dla każdej cechy względem każdej klasy\n",
    "        for class_label in y.unique():\n",
    "            class_data = X_train[X_train[column_name] == class_label]\n",
    "            feature_mean = class_data.mean()\n",
    "            feature_std = class_data.std()\n",
    "            self.gaussian_parameters[class_label] = {}\n",
    "\n",
    "            for column in X_train.columns:\n",
    "                if column == column_name:\n",
    "                    continue\n",
    "                self.gaussian_parameters[class_label][column] = (feature_mean[column], feature_std[column])\n",
    "\n",
    "    @staticmethod\n",
    "    def log_gaussian_density(x, mean, std):\n",
    "        \"\"\"\n",
    "        Oblicza logarytm funkcji Gaussa (gęstości rozkładu normalnego) dla danej wartości x.\n",
    "\n",
    "        Parametry:\n",
    "        x    - wartość, dla której obliczamy funkcję gęstości\n",
    "        mean - średnia rozkładu\n",
    "        std  - odchylenie standardowe rozkładu\n",
    "\n",
    "        Zwraca:\n",
    "        Logarytm wartości funkcji Gaussa dla zadanych parametrów.\n",
    "        \"\"\"\n",
    "        eps = 1e-9  # Mała wartość, aby uniknąć dzielenia przez zero\n",
    "        coeff = -0.5 * np.log(2.0 * np.pi * (std**2 + eps))\n",
    "        exponent = -((x - mean)**2) / (2.0 * (std**2 + eps))\n",
    "        return coeff + exponent\n",
    "\n",
    "    def predict_with_option(self, row_to_predict, return_single):\n",
    "        \"\"\"\n",
    "        Przewiduje klasy dla dostarczonego wiersza z opcją zwracania prawdopodobieństw.\n",
    "\n",
    "        Parametry:\n",
    "        row_to_predict - Series zawierający dane wejściowe do predykcji\n",
    "        return_single - jeśli True, zwraca pojedynczą przewidywaną klasę, jeśli False zwraca prawdopodobieństwa\n",
    "\n",
    "        Zwraca:\n",
    "        Jeśli return_single=True -> przewidywana klasa (str)\n",
    "        Jeśli return_single=False -> lista prawdopodobieństw dla każdej klasy\n",
    "        \"\"\"\n",
    "        log_probability_per_class = {}\n",
    "\n",
    "        # Obliczanie logarytmicznego prawdopodobieństwa dla każdej klasy\n",
    "        for class_label in self.class_log_probability:\n",
    "            log_probability = self.class_log_probability[class_label]\n",
    "\n",
    "            for column, value in row_to_predict.items():\n",
    "                if column == self.target_column:\n",
    "                    continue\n",
    "\n",
    "                if column in self.gaussian_parameters[class_label]:\n",
    "                    mean, std = self.gaussian_parameters[class_label][column]\n",
    "                    log_probability += self.log_gaussian_density(value, mean, std)\n",
    "                else:\n",
    "                    log_probability += self.epsilon  # Brak warunku oznacza bardzo małe prawdopodobieństwo\n",
    "\n",
    "            log_probability_per_class[class_label] = log_probability\n",
    "\n",
    "        # Zwracanie wyniku w zależności od opcji return_single\n",
    "        if return_single:\n",
    "            return max(log_probability_per_class, key=log_probability_per_class.get)\n",
    "        else:\n",
    "            return {class_label: np.exp(log_prob) for class_label, log_prob in log_probability_per_class.items()}\n",
    "\n",
    "    def predict(self, row_to_predict):\n",
    "        \"\"\"\n",
    "        Przewiduje klasę dla pojedynczego wiersza danych.\n",
    "\n",
    "        Parametry:\n",
    "        row_to_predict - Series zawierający dane wejściowe do predykcji\n",
    "\n",
    "        Zwraca:\n",
    "        Przewidywana klasa (str)\n",
    "        \"\"\"\n",
    "        return self.predict_with_option(row_to_predict, True)\n",
    "\n",
    "    def predict_proba(self, row_to_predict):\n",
    "        \"\"\"\n",
    "        Zwraca prawdopodobieństwa dla każdej klasy dla pojedynczego wiersza danych.\n",
    "\n",
    "        Parametry:\n",
    "        row_to_predict - Series zawierający dane wejściowe do predykcji\n",
    "\n",
    "        Zwraca:\n",
    "        Słownik prawdopodobieństw dla każdej klasy\n",
    "        \"\"\"\n",
    "        return self.predict_with_option(row_to_predict, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42a9e8",
   "metadata": {},
   "source": [
    "### Ocena modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b6de1f",
   "metadata": {},
   "source": [
    "Do wykonania poniższego kodu należy wykonać kod obu klas: MultinomialNaiveBayesClassifier oraz GaussianNaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e761894",
   "metadata": {},
   "source": [
    "**Funkcje używane do oceny dokładności modelów**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3422c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testuje model na zadanych parametrach, i zwraca te tablice - jedna poprawnego wyniku, a druga przewidywanego\n",
    "def test_model(_model: MultinomialNaiveBayesClassifier | GaussianNaiveBayesClassifier,\n",
    "                     _set: pd.DataFrame, \n",
    "                     _target_column, \n",
    "                     _test_size: float=0.2, \n",
    "                     _epsilon=1e-6, \n",
    "                     _seed: int = None\n",
    "        ) -> tuple[np.array, np.array]:\n",
    "    \n",
    "    # Podział na zbiory treningowy i testowy\n",
    "    X_train, X_test = train_test_split(_set, test_size=_test_size, random_state=_seed)\n",
    "\n",
    "    # trenujemy model\n",
    "    classifier = _model()\n",
    "    classifier.fit(X_train, column_name=_target_column, epsilon=_epsilon)\n",
    "\n",
    "    #obliczanie dokladnosci\n",
    "    total_samples = len(X_test)\n",
    "\n",
    "    predicted = []\n",
    "    correct = []\n",
    "\n",
    "    for i in range(total_samples):\n",
    "        predicted.append(classifier.predict(X_test.iloc[i]))\n",
    "        correct.append(X_test[_target_column].iloc[i])\n",
    "\n",
    "    return np.array(correct), np.array(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8eb4a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def print_report(correct: np.array, predict: np.array, set_name = \"\") -> None:\n",
    "    print(f\"Ocena klasyfikatora dla zbioru {set_name}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(correct, predict):.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(correct, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5a589",
   "metadata": {},
   "source": [
    "**Analiza Mushrooms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747fce97",
   "metadata": {},
   "source": [
    "Do wykonania poniższego kodu należy wykonać funkcje używane do oceny modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1542bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mushrooms_analysis:\n",
    "    # Ścieżka do pliku CSV z danymi o grzybach\n",
    "    file_path = \"./mushroom-classification/mushrooms.csv\"\n",
    "    \n",
    "    # Wczytanie danych do DataFrame\n",
    "    mushrooms = pd.read_csv(file_path)\n",
    "    \n",
    "    # Nazwa kolumny zawierającej klasy (jadalny/trujący)\n",
    "    target_column = 'class'\n",
    "    \n",
    "    # Model klasyfikacyjny\n",
    "    model = MultinomialNaiveBayesClassifier\n",
    "\n",
    "    # Parametry klasy\n",
    "    seed : int  # Losowe ziarno\n",
    "    test_size : float  # Procentowy podział danych na zbiór testowy\n",
    "\n",
    "    def __init__(self, test_size : float = 0.3, seed : int = None):\n",
    "        # Inicjalizacja parametrów\n",
    "        self.seed = seed\n",
    "        self.test_size = test_size\n",
    "\n",
    "    def print_report(self):\n",
    "        # Testowanie modelu i uzyskanie wyników klasyfikacji\n",
    "        y_test_mush, y_pred_mush = test_model(_model=self.model, \n",
    "                                              _target_column=self.target_column, \n",
    "                                              _set=self.mushrooms, \n",
    "                                              _test_size=0.3,\n",
    "                                              _seed=self.seed)\n",
    "\n",
    "        # Wyświetlenie raportu klasyfikacji\n",
    "        print_report(y_test_mush, y_pred_mush, \"Mushrooms\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test_mush, y_pred_mush))\n",
    "    \n",
    "    def print_coorelation_matrix(self):\n",
    "        # Zakodowanie zmiennych kategorycznych jako zmienne binarne\n",
    "        mush_encoded = pd.get_dummies(self.mushrooms.drop(columns=[\"class\"]))\n",
    "\n",
    "        # Rysowanie macierzy korelacji\n",
    "        plt.figure(figsize=(12,8))\n",
    "        sns.heatmap(mush_encoded.corr(), cmap=\"coolwarm\")\n",
    "        plt.title(\"Macierz korelacji dla Mushrooms\")\n",
    "        plt.show()\n",
    "    \n",
    "    def print_ROC_curve(self):\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "        # Wczytanie zbioru danych\n",
    "        file_path = \"./mushroom-classification/mushrooms.csv\"\n",
    "        mushrooms = pd.read_csv(file_path)\n",
    "\n",
    "        # Definiowanie kolumny docelowej i modelu\n",
    "        target_column = 'class'\n",
    "        model = MultinomialNaiveBayesClassifier\n",
    "\n",
    "        # Testowanie modelu\n",
    "        y_test_mush, y_pred_mush = test_model(_model=model, \n",
    "                                              _target_column=target_column, \n",
    "                                              _set=mushrooms, \n",
    "                                              _test_size=0.2)\n",
    "\n",
    "        # Przekształcenie etykiet klas: 'e' -> 0, 'p' -> 1\n",
    "        y_test_mush[y_test_mush == 'e'] = 0\n",
    "        y_test_mush[y_test_mush == 'p'] = 1\n",
    "        y_pred_mush[y_pred_mush == 'e'] = 0\n",
    "        y_pred_mush[y_pred_mush == 'p'] = 1\n",
    "        y_test_mush = y_test_mush.astype('int') \n",
    "        y_pred_mush = y_pred_mush.astype('int') \n",
    "\n",
    "        # Obliczenie krzywej ROC i pola pod krzywą (AUC)\n",
    "        fpr, tpr, _ = roc_curve(y_test_mush, y_pred_mush)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Rysowanie krzywej ROC\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curve dla Mushrooms\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Funkcja wyświetlająca wykres skuteczności modelu w zależności od rozmiaru zbioru treningowego\n",
    "    def plot_accuracy_of_test_size(self):\n",
    "        x = [i for i in range(1,100)]  # Lista rozmiarów zbioru treningowego [%]\n",
    "        y = []  # Lista skuteczności modelu\n",
    "\n",
    "        # Iteracja po różnych rozmiarach zbioru treningowego\n",
    "        for i in range(1,100):   \n",
    "            y_test_iris, y_pred_iris = test_model(_model=self.model, \n",
    "                                                  _target_column=self.target_column, \n",
    "                                                  _set=self.mushrooms, \n",
    "                                                  _test_size=1-(i/100))  # Rozmiar zbioru testowego\n",
    "            \n",
    "            y.append(round(accuracy_score(y_test_iris, y_pred_iris) * 100))  # Obliczenie skuteczności\n",
    "\n",
    "        # Rysowanie wykresu skuteczności w zależności od rozmiaru zbioru treningowego\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel(\"Rozmiar zbioru treningowego [%]\")\n",
    "        plt.ylabel(\"Uzyskana skuteczność modelu [%]\")\n",
    "        plt.title(\"Wykres skuteczności od rozmiaru zbioru treningowego\")\n",
    "        plt.show()\n",
    "\n",
    "# Utworzenie instancji klasy do analizy zbioru grzybów\n",
    "mushrooms_analysis = Mushrooms_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca36652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generowanie wykresu zależności dokładności modelu od rozmiaru zbioru treningowego\n",
    "mushrooms_analysis.plot_accuracy_of_test_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1574d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generowanie raportu z oceną klasyfikatora\n",
    "mushrooms_analysis.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3421c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generowanie krzywej ROC (receiver operating characteristic curve)\n",
    "mushrooms_analysis.print_ROC_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generowanie macierzy korelacji cech\n",
    "mushrooms_analysis.print_coorelation_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d0ad95",
   "metadata": {},
   "source": [
    "**Analiza Iris**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60f51416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iris_analysis:\n",
    "    # Wczytanie zbioru danych Iris\n",
    "    iris = load_iris()\n",
    "    \n",
    "    # Nazwa kolumny dla etykiet klas\n",
    "    target_column = 'species'\n",
    "    \n",
    "    # Model klasyfikacyjny\n",
    "    model = GaussianNaiveBayesClassifier\n",
    "\n",
    "    def print_3d_data(self):\n",
    "        from sklearn.decomposition import PCA\n",
    "\n",
    "        # Tworzenie figury 3D\n",
    "        fig = plt.figure(1, figsize=(8, 6))\n",
    "        ax = fig.add_subplot(111, projection=\"3d\", elev=-150, azim=110)\n",
    "\n",
    "        # Redukcja wymiarów danych do 3D za pomocą PCA\n",
    "        X_reduced = PCA(n_components=3).fit_transform(self.iris.data)\n",
    "        \n",
    "        # Rysowanie punktów w przestrzeni 3D\n",
    "        ax.scatter(\n",
    "            X_reduced[:, 0],\n",
    "            X_reduced[:, 1],\n",
    "            X_reduced[:, 2],\n",
    "            c=self.iris.target,\n",
    "            s=40,\n",
    "        )\n",
    "\n",
    "        # Ustawienia wykresu\n",
    "        ax.set_title(\"First three PCA dimensions\")\n",
    "        ax.set_xlabel(\"1st Eigenvector\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.set_ylabel(\"2nd Eigenvector\")\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.set_zlabel(\"3rd Eigenvector\")\n",
    "        ax.zaxis.set_ticklabels([])\n",
    "\n",
    "        # Wyświetlenie wykresu\n",
    "        plt.show()\n",
    "\n",
    "    def print_report(self):\n",
    "        # Tworzenie DataFrame na podstawie danych Iris\n",
    "        iris_df = pd.DataFrame(self.iris.data, columns=self.iris.feature_names)\n",
    "        iris_df[self.target_column] = self.iris.target  # Dodanie kolumny z etykietami klas\n",
    "\n",
    "        # Testowanie modelu i uzyskanie wyników klasyfikacji\n",
    "        y_test_iris, y_pred_iris = test_model(_model=self.model, \n",
    "                                              _target_column=self.target_column, \n",
    "                                              _set=iris_df, \n",
    "                                              _test_size=0.3)\n",
    "\n",
    "        # Wyświetlenie raportu klasyfikacji\n",
    "        print_report(y_test_iris, y_pred_iris)\n",
    "    \n",
    "    # Funkcja wyświetlająca wykres skuteczności modelu w zależności od rozmiaru zbioru treningowego\n",
    "    def plot_accuracy_of_test_size(self):\n",
    "        # Tworzenie DataFrame na podstawie danych Iris\n",
    "        iris_df = pd.DataFrame(self.iris.data, columns=self.iris.feature_names)\n",
    "        iris_df[self.target_column] = self.iris.target  # Dodanie kolumny z etykietami klas\n",
    "\n",
    "        x = [i*10 for i in range(1,10)]  # Lista rozmiarów zbioru treningowego [%]\n",
    "        y = []  # Lista skuteczności modelu\n",
    "\n",
    "        # Iteracja po różnych rozmiarach zbioru treningowego\n",
    "        for i in range(1,10):   \n",
    "            y_test_iris, y_pred_iris = test_model(_model=self.model, \n",
    "                                                  _target_column=self.target_column, \n",
    "                                                  _set=iris_df, \n",
    "                                                  _test_size=1-(i/10))  # Rozmiar zbioru testowego\n",
    "            \n",
    "            y.append(round(accuracy_score(y_test_iris, y_pred_iris) * 100))  # Obliczenie skuteczności\n",
    "\n",
    "        # Rysowanie wykresu skuteczności w zależności od rozmiaru zbioru treningowego\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel(\"Rozmiar zbioru treningowego [%]\")\n",
    "        plt.ylabel(\"Uzyskana skuteczność modelu [%]\")\n",
    "        plt.title(\"Wykres skuteczności od rozmiaru zbioru treningowego\")\n",
    "        plt.show()\n",
    "\n",
    "# Utworzenie instancji klasy do analizy zbioru Iris\n",
    "iris_analysis = Iris_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten wykres dobrze obrazuje rozdzielenie gatunków irysa\n",
    "iris_analysis.print_3d_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generowanie raportu z oceną klasyfikatora\n",
    "iris_analysis.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generowanie wykresu skuteczności od rozmiaru zbioru treningowego\n",
    "iris_analysis.plot_accuracy_of_test_size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
